"""add_derived_cols.py
--------------------------------
Append derived technical indicators (ATR, volume averages, momentum, NK225 GAP
etc.) to ``backtest_data/price_ohlcv.csv`` and write the result to
``backtest_data/price_ohlcv_derived.csv``.

This script **does not call any J‑Quants API**. All inputs are local CSV／pickle
files generated by the upstream ETL step (``generate_price_csv.py`` and
``make_premium_pickle.py``). Therefore refresh／ID tokens are **not acquired**
any more.
"""
from __future__ import annotations

from pathlib import Path

import numpy as np
import pandas as pd

from app.core.config import load_config
from app.core.logger import setup_logger

# -----------------------------------------------------------------------------
# Constants & paths
# -----------------------------------------------------------------------------
RAW_CSV = Path("backtest_data/price_ohlcv.csv")
DERIVED_CSV = Path("backtest_data/price_ohlcv_derived.csv")
NK225_CSV = Path("backtest_data/nk225_gap.csv")  # produced elsewhere


# -----------------------------------------------------------------------------
# Helper functions
# -----------------------------------------------------------------------------

def add_derived_cols(df: pd.DataFrame) -> pd.DataFrame:
    """Return a DataFrame with derived indicators.

    Parameters
    ----------
    df : pd.DataFrame
        Raw OHLCV price DataFrame. Must contain columns ``[Date, High, Low,\
        Close, Volume]``.

    Returns
    -------
    pd.DataFrame
        Same records with additional columns:
        ``ATR_1``, ``ATR_5``, ``ATR_20``, ``Vol_5``, ``Vol_20``,
        ``Momentum_2``, ``PullUp``, ``NK225_gap``
    """
    df = df.copy()

    # --- ATR -----------------------------------------------------------------
    df["ATR_1"] = df["High"] - df["Low"]
    df["ATR_5"] = df["ATR_1"].rolling(window=5, min_periods=5).mean()
    df["ATR_20"] = df["ATR_1"].rolling(window=20, min_periods=20).mean()

    # --- Volume averages -----------------------------------------------------
    df["Vol_5"] = df["Volume"].rolling(window=5, min_periods=5).mean()
    df["Vol_20"] = df["Volume"].rolling(window=20, min_periods=20).mean()

    # --- Momentum (2‑day) -----------------------------------------------------
    df["Momentum_2"] = df["Close"].pct_change(periods=2)

    # --- Pull‑up ratio --------------------------------------------------------
    prev_low = df["Low"].shift(1)
    prev_high = df["High"].shift(1)
    prev_close = df["Close"].shift(1)
    df["PullUp"] = (prev_close - prev_low) / (prev_high - prev_low) + 0.5

    # --- NK225 gap merge ------------------------------------------------------
    if NK225_CSV.exists():
        nk225 = pd.read_csv(NK225_CSV)
        df["Date"] = pd.to_datetime(df["Date"]).dt.normalize()
        nk225["Date"] = pd.to_datetime(nk225["Date"]).dt.normalize()
        df = df.merge(nk225[["Date", "NK225_gap"]], on="Date", how="left")
    else:
        df["NK225_gap"] = np.nan

        # ------------------------------------------------------------------
    # Additional columns required by score_up
    # ------------------------------------------------------------------
    # 3‑day momentum (Close_{t} / Close_{t‑3} − 1)
    df["Momentum_3"] = df.groupby("Code")["Close"].pct_change(3)

    # Rolling ATR averages (3‑day, 10‑day) – ATR_1 already exists
    df["ATR_3"] = (
        df.groupby("Code")["ATR_1"].transform(lambda x: x.rolling(window=3, min_periods=1).mean())
    )
    df["ATR_10"] = (
        df.groupby("Code")["ATR_1"].transform(lambda x: x.rolling(window=10, min_periods=1).mean())
    )

    # Simple moving average (5‑day) for trend filter in score_up
    df["MA_5"] = (
        df.groupby("Code")["Close"].transform(lambda x: x.rolling(window=5, min_periods=1).mean())
    )

        # 昨日のレンジ (前日 ATR_1)
    df["Range_yesterday"] = df.groupby("Code")["ATR_1"].shift(1)

    return df


# -----------------------------------------------------------------------------
# Main routine
# -----------------------------------------------------------------------------

def main() -> None:
    cfg = load_config("configs/config.yaml")
    logger = setup_logger(cfg.logging)

    if not RAW_CSV.exists():
        logger.error("Input file not found: %s", RAW_CSV)
        raise SystemExit(1)

    logger.info("Loading %s", RAW_CSV)
    raw = pd.read_csv(RAW_CSV)

    derived = add_derived_cols(raw)

    DERIVED_CSV.parent.mkdir(parents=True, exist_ok=True)
    derived.to_csv(DERIVED_CSV, index=False)

    logger.info("Written %s (%d rows, %d columns)", DERIVED_CSV, *derived.shape)


if __name__ == "__main__":
    main()
